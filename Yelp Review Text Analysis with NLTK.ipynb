{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Working with Yelp Review Text using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read in review data\n",
    "\n",
    "## Commented this out; created a smaller csv to work with because my computer can't handle \n",
    "## reviews and business data simultaneously.\n",
    "\n",
    "## To get the full dataset, uncomment the below: \n",
    "#rvws = pd.read_csv(\"data\\yelp_academic_dataset_review.csv\")\n",
    "\n",
    "## Below csv was created previously using the first 5,000 reviews. Once this is a working model we can expand it to a fuller dataset.\n",
    "#rvws = reviews.iloc[:5000,:]\n",
    "#rvws.to_csv(\"yelp_dataset_5k_review.csv\")\n",
    "rvws = pd.read_csv(\"data\\yelp_dataset_5k_review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## To make things easier when trying to analyze the text, let's just look at restaurants. For that, we'll have to join the review\n",
    "## and business data. I'm also puling the city and state so I can add location later on if I desire to.\n",
    "\n",
    "headers = ['categories','business_id','city','state']\n",
    "business = pd.read_csv(\"data\\yelp_academic_dataset_business.csv\", usecols = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Now that we have the data joined with the business information, we can narrow the dataset to just restaurants so that\n",
    "## the language we are looking for is more consistent. \n",
    "## (e.g. a good doctor review will have differnt language than a good restaurant review)\n",
    "\n",
    "reviews = pd.merge(rvws, business, on = 'business_id')\n",
    "cat = reviews['categories']\n",
    "rest = []\n",
    "\n",
    "for x in range(len(cat)):\n",
    "    if \"Restaurants\" in cat[x]:\n",
    "        rest.append(1)\n",
    "    elif \"Food\" in cat[x]:\n",
    "        rest.append(1)\n",
    "    else:\n",
    "        rest.append(0)\n",
    "\n",
    "reviews['restaurant'] = rest\n",
    "\n",
    "## This will modify our reviews DataFrame to only include business that fall into the \"restaurants\" category.\n",
    "\n",
    "reviews = reviews[reviews['restaurant'] == 1]\n",
    "reviews = reviews.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3735"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = reviews['text']\n",
    "stars = reviews['stars']\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>votes.cool</th>\n",
       "      <th>business_id</th>\n",
       "      <th>votes.funny</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>votes.useful</th>\n",
       "      <th>categories</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>LWbYpcangjBMm4KPxZGOKg</td>\n",
       "      <td>6w6gMZ3iBLGcUM4RBIuifQ</td>\n",
       "      <td>This place was DELICIOUS!!  My parents saw a r...</td>\n",
       "      <td>0</td>\n",
       "      <td>mVHrayjG3uZ_RLHkLj-AMg</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>review</td>\n",
       "      <td>5</td>\n",
       "      <td>[u'Bars', u'American (New)', u'Nightlife', u'L...</td>\n",
       "      <td>PA</td>\n",
       "      <td>Braddock</td>\n",
       "      <td>1</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>m1FpV3EAeggaAdfPx0hBRQ</td>\n",
       "      <td>jVVv_DA5mCDB6mediuwHAw</td>\n",
       "      <td>Can't miss stop for the best Fish Sandwich in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>mVHrayjG3uZ_RLHkLj-AMg</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-03-15</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>[u'Bars', u'American (New)', u'Nightlife', u'L...</td>\n",
       "      <td>PA</td>\n",
       "      <td>Braddock</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>8fApIAMHn2MZJFUiCQto5Q</td>\n",
       "      <td>3Es8GsjkssusYgeU6_ZVpQ</td>\n",
       "      <td>This place should have a lot more reviews - bu...</td>\n",
       "      <td>1</td>\n",
       "      <td>mVHrayjG3uZ_RLHkLj-AMg</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-03-30</td>\n",
       "      <td>review</td>\n",
       "      <td>2</td>\n",
       "      <td>[u'Bars', u'American (New)', u'Nightlife', u'L...</td>\n",
       "      <td>PA</td>\n",
       "      <td>Braddock</td>\n",
       "      <td>1</td>\n",
       "      <td>1216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>uK8tzraOp4M5u3uYrqIBXg</td>\n",
       "      <td>KAkcn7oQP1xX8KsZ-XmktA</td>\n",
       "      <td>This place was very good. I found out about Em...</td>\n",
       "      <td>0</td>\n",
       "      <td>mVHrayjG3uZ_RLHkLj-AMg</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-10-20</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>[u'Bars', u'American (New)', u'Nightlife', u'L...</td>\n",
       "      <td>PA</td>\n",
       "      <td>Braddock</td>\n",
       "      <td>1</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>6wvlM5L4_EroGXbnb_92xQ</td>\n",
       "      <td>BZNJkkP0bXnwQ2-sCqat2Q</td>\n",
       "      <td>Old school.....traditional \"mom 'n pop\" qualit...</td>\n",
       "      <td>0</td>\n",
       "      <td>mVHrayjG3uZ_RLHkLj-AMg</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-11-07</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>[u'Bars', u'American (New)', u'Nightlife', u'L...</td>\n",
       "      <td>PA</td>\n",
       "      <td>Braddock</td>\n",
       "      <td>1</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 user_id               review_id  \\\n",
       "0          22  LWbYpcangjBMm4KPxZGOKg  6w6gMZ3iBLGcUM4RBIuifQ   \n",
       "1          23  m1FpV3EAeggaAdfPx0hBRQ  jVVv_DA5mCDB6mediuwHAw   \n",
       "2          24  8fApIAMHn2MZJFUiCQto5Q  3Es8GsjkssusYgeU6_ZVpQ   \n",
       "3          25  uK8tzraOp4M5u3uYrqIBXg  KAkcn7oQP1xX8KsZ-XmktA   \n",
       "4          26  6wvlM5L4_EroGXbnb_92xQ  BZNJkkP0bXnwQ2-sCqat2Q   \n",
       "\n",
       "                                                text  votes.cool  \\\n",
       "0  This place was DELICIOUS!!  My parents saw a r...           0   \n",
       "1  Can't miss stop for the best Fish Sandwich in ...           0   \n",
       "2  This place should have a lot more reviews - bu...           1   \n",
       "3  This place was very good. I found out about Em...           0   \n",
       "4  Old school.....traditional \"mom 'n pop\" qualit...           0   \n",
       "\n",
       "              business_id  votes.funny  stars        date    type  \\\n",
       "0  mVHrayjG3uZ_RLHkLj-AMg            0      5  2012-12-01  review   \n",
       "1  mVHrayjG3uZ_RLHkLj-AMg            0      5  2013-03-15  review   \n",
       "2  mVHrayjG3uZ_RLHkLj-AMg            0      5  2013-03-30  review   \n",
       "3  mVHrayjG3uZ_RLHkLj-AMg            0      4  2013-10-20  review   \n",
       "4  mVHrayjG3uZ_RLHkLj-AMg            0      5  2013-11-07  review   \n",
       "\n",
       "   votes.useful                                         categories state  \\\n",
       "0             5  [u'Bars', u'American (New)', u'Nightlife', u'L...    PA   \n",
       "1             0  [u'Bars', u'American (New)', u'Nightlife', u'L...    PA   \n",
       "2             2  [u'Bars', u'American (New)', u'Nightlife', u'L...    PA   \n",
       "3             1  [u'Bars', u'American (New)', u'Nightlife', u'L...    PA   \n",
       "4             0  [u'Bars', u'American (New)', u'Nightlife', u'L...    PA   \n",
       "\n",
       "       city  restaurant  text_length  \n",
       "0  Braddock           1         1038  \n",
       "1  Braddock           1           57  \n",
       "2  Braddock           1         1216  \n",
       "3  Braddock           1          401  \n",
       "4  Braddock           1          217  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's create some data based on the text so we can run some regressions on characteristics of the text.\n",
    "\n",
    "text_length = []\n",
    "for x in range(len(reviews['text'])):\n",
    "    text_length.append(len(text[x]))\n",
    "\n",
    "reviews['text_length'] = text_length\n",
    "reviews.head()\n",
    "#reviews['text_length'] = len(reviews['text'])\n",
    "#reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Downloads from here: http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\n",
    "## Grab a generic words of positive and negative words; we are going to use these to get a sentiment score out of the text.\n",
    "\n",
    "positives = open('data/positive-words.txt').read()\n",
    "negatives = open('data/negative-words.txt').read()\n",
    "pos_word_list = positives.split('\\n')\n",
    "neg_word_list = negatives.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create function to output list of words in given list from a sentence.\n",
    "\n",
    "def review_to_wordlist(review, remove_stopwords=False):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "\n",
    "    review_text = review   \n",
    "    \n",
    "    # 1. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "\n",
    "    # 2. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "\n",
    "    # 5. Return a list of words\n",
    "    return(words)\n",
    "\n",
    "def word_count(sentence, word_list):\n",
    "    count = 0\n",
    "    for x in review_to_wordlist(sentence):\n",
    "        if x in word_list:\n",
    "            count += 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## In an initial run of this test, two separate values were created, which counted the positive and negative words in the corpus.\n",
    "## Upon further review, this was deleted and replace with a sentiment score which was 1 for all positive words\n",
    "## and -1 for all negative words\n",
    "\n",
    "#pos_word_count = []\n",
    "#neg_word_count = []\n",
    "#pos_neg_ratio = []\n",
    "#for x in text:\n",
    "#    positive = word_count(x, pos_word_list)\n",
    "#    negative = word_count(x, neg_word_list)\n",
    "#    if (negative > 0):\n",
    "#        ratio = float(positive)/negative\n",
    "#    else:\n",
    "#        ratio = positive\n",
    "#    \n",
    "#    if ((positive + negative) == 0):\n",
    "#        sent = 0\n",
    "#    else:\n",
    "#        sent = ((positive-negative)/(float(positive)+negative))\n",
    "#        \n",
    "#    pos_word_count.append(positive)\n",
    "#    neg_word_count.append(negative)\n",
    "#    pos_neg_ratio.append(ratio)\n",
    "\n",
    "#reviews['pos_word_count'] = pos_word_count\n",
    "#reviews['neg_word_count'] = neg_word_count\n",
    "#reviews['sentiment'] = sentiment\n",
    "#reviews['pos_neg_ratio'] = pos_neg_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Use positive and negative words to give each piece of a text a sentiment score\n",
    "\n",
    "sentiment = []\n",
    "pos_neg_ratio = []\n",
    "count = 0\n",
    "for x in text:\n",
    "    positive = word_count(x, pos_word_list)\n",
    "    negative = word_count(x, neg_word_list)\n",
    "    if (negative > 0):\n",
    "        ratio = float(positive)/negative\n",
    "    else:\n",
    "        ratio = positive\n",
    "    \n",
    "    if ((positive + negative) == 0):\n",
    "        sent = 1\n",
    "    else:\n",
    "        sent = ((positive-negative)/(float(positive)+negative))+1\n",
    "        \n",
    "    sentiment.append(sent)\n",
    "    pos_neg_ratio.append(ratio)\n",
    "    if count % 1000 == 0:\n",
    "        print \"Scoring text #{}\".format(count)\n",
    "    count += 1\n",
    "\n",
    "reviews['sentiment'] = sentiment\n",
    "reviews['pos_neg_ratio'] = pos_neg_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Features used for initial pass: text length, ratio of positive to negative words, and sentiment.\n",
    "\n",
    "feature_list = ['text_length', 'pos_neg_ratio', 'sentiment']\n",
    "features = reviews[feature_list]\n",
    "stars = reviews[['stars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Test using Various models. Set up the train test split first, then fit various models and see how they perform.\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samchu\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\samchu\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:449: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree score: 0.321141837645\n",
      "Random Forest score: 0.316681534344\n",
      "Multinomial Naive Bayes score: 0.351471900089\n"
     ]
    }
   ],
   "source": [
    "## Fit various models\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(features, stars, test_size=0.3, random_state=12)\n",
    "tree = DecisionTreeClassifier()\n",
    "forest = RandomForestClassifier()\n",
    "mnbayes = MultinomialNB()\n",
    "\n",
    "tree.fit(x_train, y_train)\n",
    "forest.fit(x_train, y_train)\n",
    "mnbayes.fit(x_train, y_train)\n",
    "\n",
    "print \"Decision Tree score: {}\".format(tree.score(x_test, y_test))\n",
    "print \"Random Forest score: {}\".format(forest.score(x_test, y_test))\n",
    "print \"Multinomial Naive Bayes score: {}\".format(mnbayes.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Before trying to move on to a new method, let's make this a binary predictor by\n",
    "## separating reviews into \"good\" (4-5 stars) and \"bad\" (1-3 stars)\n",
    "\n",
    "# Playing with different star thresholds for what we consider a \"good\" or \"bad\" review.\n",
    "star_threshold = 4\n",
    "\n",
    "reviews['good'] = (reviews['stars'] >= star_threshold)\n",
    "good = reviews['good']\n",
    "good = good.map({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree score: 0.648528099911\n",
      "Random Forest score: 0.680642283675\n",
      "Multinomial Naive Bayes score: 0.696699375558 \n",
      "\n",
      "Decision Tree AUC: 0.637084747433\n",
      "Random Forest AUC: 0.699280111998\n",
      "Multinomial Naive Bayes AUC: 0.727446155714\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(features, good, test_size=0.3, random_state=12)\n",
    "tree = DecisionTreeClassifier()\n",
    "forest = RandomForestClassifier()\n",
    "mnbayes = MultinomialNB()\n",
    "\n",
    "tree.fit(x_train, y_train)\n",
    "forest.fit(x_train, y_train)\n",
    "mnbayes.fit(x_train, y_train)\n",
    "\n",
    "print \"Decision Tree score: {}\".format(tree.score(x_test, y_test))\n",
    "print \"Random Forest score: {}\".format(forest.score(x_test, y_test))\n",
    "print \"Multinomial Naive Bayes score: {} \\n\".format(mnbayes.score(x_test, y_test))\n",
    "\n",
    "print \"Decision Tree AUC: {}\".format(cross_val_score(tree, features, good, cv=10, scoring='roc_auc').mean())\n",
    "print \"Random Forest AUC: {}\".format(cross_val_score(forest, features, good, cv=10, scoring='roc_auc').mean())\n",
    "print \"Multinomial Naive Bayes AUC: {}\".format(cross_val_score(mnbayes, features, good, cv=10, scoring='roc_auc').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##Let's manipulate the data a little more, then vectorize the text and fit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [This, place, DELICIOUS, My, parents, saw, rec...\n",
       "1    [Can, miss, stop, best, Fish, Sandwich, Pittsb...\n",
       "2    [This, place, lot, reviews, I, m, glad, doesn,...\n",
       "3    [This, place, good, I, found, Emil, watching, ...\n",
       "4    [Old, school, traditional, mom, n, pop, qualit...\n",
       "5    [Seen, restaurant, best, places, Pittsburgh, R...\n",
       "6    [Wonderful, reuben, Map, shown, Yelp, page, in...\n",
       "7                               [Good, fish, sandwich]\n",
       "8    [After, morning, Thrift, Store, hunting, frien...\n",
       "9    [This, hidden, gem, really, It, took, us, fore...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = reviews['text']\n",
    "text = text[:10]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning text #500...\n",
      "Cleaning text #1000...\n",
      "Cleaning text #1500...\n",
      "Cleaning text #2000...\n",
      "Cleaning text #2500...\n",
      "Cleaning text #3000...\n",
      "Cleaning text #3500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samchu\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "## Let's work with the text before vectorizing. We're going to get rid of stop words and non-letters.\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "count = 0\n",
    "text_clean = text\n",
    "\n",
    "for x in range(len(text_clean)):\n",
    "    count +=1\n",
    "    if count % 500 == 0:\n",
    "        print \"Cleaning text #{}...\".format(count)\n",
    "    w = text[x]\n",
    "    w = re.sub(\"[^a-zA-Z]\",\" \", w)\n",
    "    w = word_tokenize(w)\n",
    "    w = [z for z in w if not z in stop_words]\n",
    "    text_clean[x] = w\n",
    "\n",
    "text_clean = [' , '.join(z).strip() for z in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-96-aafa76c33039>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-96-aafa76c33039>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    asdfg = join(z).strip() for z in asdf\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## Lemmatize the text... eventually we want to insert this into the box above so that it loops through the list\n",
    "## only once and works through the text in one pass.\n",
    "\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "#\n",
    "#lemmatizer=WordNetLemmatizer()\n",
    "#\n",
    "#for w in text:\n",
    "#    w = lemmatizer.lemmatize(w)\n",
    "\n",
    "#traindf['ingredients_clean_string'] = [' , '.join(z).strip() for z in traindf['ingredients']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Vectorize the text with sklearn's CountVectorizer.\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(decode_error = 'ignore')\n",
    "vect.fit(text_clean)\n",
    "text_dtm = vect.transform(text_clean)\n",
    "text_array = text_dtm.toarray()\n",
    "text_df = pd.DataFrame(text_array, columns = vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree score: 0.363068688671\n",
      "Random Forest score: 0.348795718109\n",
      "Multinomial Naive Bayes score: 0.448706512043\n"
     ]
    }
   ],
   "source": [
    "## Initial test by running the test on the vectorization of the text.\n",
    "\n",
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(text_array, stars, test_size=0.3, random_state=12)\n",
    "tree = DecisionTreeClassifier()\n",
    "forest = RandomForestClassifier()\n",
    "mnbayes = MultinomialNB()\n",
    "\n",
    "tree.fit(x_train, y_train)\n",
    "forest.fit(x_train, y_train)\n",
    "mnbayes.fit(x_train, y_train)\n",
    "\n",
    "print \"Decision Tree score: {}\".format(tree.score(x_test, y_test))\n",
    "print \"Random Forest score: {}\".format(forest.score(x_test, y_test))\n",
    "print \"Multinomial Naive Bayes score: {}\".format(mnbayes.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per the above results, this performed slightly better than the model generated with the sentiment score, positive/negative ratio and length of text. Multinomial Naive Bayes performed the best so far as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree score: 0.693131132917\n",
      "Random Forest score: 0.743086529884\n",
      "Multinomial Naive Bayes score: 0.817127564674 \n",
      "\n",
      "Decision Tree AUC: 0.674537784076\n",
      "Random Forest AUC: 0.766679499683\n",
      "Multinomial Naive Bayes AUC: 0.790659426578\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(text_array, good, test_size=0.3, random_state=12)\n",
    "tree = DecisionTreeClassifier()\n",
    "forest = RandomForestClassifier()\n",
    "mnbayes = MultinomialNB()\n",
    "\n",
    "tree.fit(x_train, y_train)\n",
    "forest.fit(x_train, y_train)\n",
    "mnbayes.fit(x_train, y_train)\n",
    "\n",
    "print \"Decision Tree score: {}\".format(tree.score(x_test, y_test))\n",
    "print \"Random Forest score: {}\".format(forest.score(x_test, y_test))\n",
    "print \"Multinomial Naive Bayes score: {} \\n\".format(mnbayes.score(x_test, y_test))\n",
    "\n",
    "print \"Decision Tree AUC: {}\".format(cross_val_score(tree, text_array, good, cv=10, scoring='roc_auc').mean())\n",
    "print \"Random Forest AUC: {}\".format(cross_val_score(forest, text_array, good, cv=10, scoring='roc_auc').mean())\n",
    "print \"Multinomial Naive Bayes AUC: {}\".format(cross_val_score(mnbayes, text_array, good, cv=10, scoring='roc_auc').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the vectorization of the words, we get a respectable AUC for MN Bayes (0.817) when testing for good / bad reviews. Let's continue to try to improve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
